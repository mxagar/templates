Docker Course by Codium
Notes by Mikel Sagardia
2021.06.09-10

Repositorio github
    https://github.com/CodiumTeam/docker-training

Topics / Overview
    Bloque 1 - Conoce Docker
    - Historia: de dónde se viene (“bare-metal”, VM, etc.)
    - Qué problemas resuelve.
    - Por qué y cuándo usarlo: ventajas frente a las alternativas.
    - Arquitectura básica y tecnologías en las que se basa. 
    - Ejercicios prácticos

    Bloque 2 - Primeros pasos: uso de elementos básicos
    - Comandos básicos
    - Puertos
    - Variables de entorno
    - Volúmenes
    - Networking
    - Docker-compose: utilidad, definición, uso y buenas prácticas
    - Ejercicios prácticos

    Bloque 3 - Cómo construir y optimizar tu propia imagen
    - Dockerfile
    - ENTRYPOINT, CMD, USER, FROM, etc.
    - Multi-stage
    - Cómo “parametrizar”: .env, ENV, build args, etc.
    - Layers
    - Best practices: e.g. caching, order, tamaño, granularidad, etc. 
    - Ejercicios prácticos

    Bloque 4 - Publicar imágenes y resolver problemas
    - Publicar y usar tus imágenes 
        - Docker hub / GitLab registry
        - Docker login + push
        - Tags, alias
        - Cómo usar las imágenes publicadas con docker-compose
    - Resolver problemas con Docker:
        - Entrar al contenedor y ver los logs
        - Estadísticas
        - Monitorización
        - Limitación de recursos del sistema utilizados
        - Limpieza
    - Ejercicios prácticos
    - Particularidades en Windows
    - Best practices
    - Recomendaciones para ampliar conocimientos.

---------

# Module 1

Why Docker?
    Docker tries to solve the diversity and difference in HW, SW, versions, configurations, etc.

VM vs Docker
    Docker is much lighter, efficient and faster than a VM, because there is no an OS running for each container
    Docker is basically the App + Bins/Libs
    Applications run like in a bubble, and we can run that bubble anywhere, that's the advantage
    Docker containers use the resources of the host OS

Docker architecture
    Docker engine has the client-server architecture
    We have a docker deamon, which is the server that provides the services
    We have an API (http) and CLI

Image vs containers
    Images contain the application + libs + config
    A container is an image which is being executed
    Thus, the image is like a template or a set of recipies to run a container
    A container is terminated when its application finishes being executed
        That is a major difference with VMs
        The applications might run very long, though

Registries
    We share images in there
    Docker HUb is a public Registry

Demo
    docker playground
        https://labs.play-with-docker.com

    docker version
    docker run hello-world
        image is downloaded if not available locally

Exercise 1

    docker run hello-world
    docker run mongo
        Ctrl+C
    docker run python:alpine python --version
    docker run ubuntu ls
    docker run -it python:alpine

Docker goals and benefits

    images are immutable: they do not change when run as containers
    thus, containers are ephimeral: changes done in them are not saved


# Module 2

Basic commands

    docker run -d nginx
        -d: detach container, it runs in the background, we get the terminal back

    docker ps
    docker container ls
        list containers that are running

    docker logs TAB
        we pass the name or id
        see logs of containers running in the background

    docker stop TAB
        pass name/id
        stop container from execution
        but we can still see the logs

    docker ps -a
    docker container ls -a
        see all containers, also the stopped ones

    docker rm TAB
        pass name/id
        remove container
        but logs are also removed!
        if we saved files and want toaccess them, we need to run the container again

    docker run --rm hello-world
        --rm: automatically remove container after finishing

    docker exec 1 ls
        we access the container which starts with 1...
        we replace 1 with a valid container name or id
        and execute another command in it: ls
        we should avoid that
        keep in mind all container should be interchangeable
        so 
    
    docker exec -it 1 sh
        we open an interactive sh terminal inside conatiner 1...

    docker run nginx ls
        we run an nginx web server
        but instead of running the web server, we ask it to run the command ls
        that doesnt make sense, its for exercise purposes only
    
    docker kill 1
        replace 1 by a valid name/id, TAB...
        like regular kill, not clean termination, but forced

Exercise 2

    See exercise with notes.

Volumes

    We can mount host directories in the container
    That way, the data we generate inside the container in the Volumes
    persists outside of it if the container is removed

    docker run -v <host path>:<container path>

    We can also create volumes
        docker volume create my_volume

Networking

    docker run -d --name my_nginx nginx
        we have not ports open
    docker run -d -p 80:80 --name my_nginx nginx
        port fowarding
        we expose ports
        docker ps
            we see forwarded ports now
    
    docker run -d -P --name my_nginx nginx
        high number free port chosen automatically
        docker ps
            we see forwarded ports

Environment Variables

    we can insert environment variables with -e in docker run
    that is super useful, because we parametrize applications with env variables

Exercise 3

    See exercises.

Docker-compose

    Sometimes we want to launch several container.
    For instance, image we'd like to publish a Wordpress page
        we need wordpress, nginx, etc.

    For that, we use docker compose: a YAML file describing how to launch containers

    Another option would be using orchestration
        that can be done with docker Swarm or Kubernetes, but that's more advanced

    Use cases for docker-compose
        setup a local environment
        we do not use distributed systems with several machines

        note: docker swarm has the same syntax as docker-compose
            we use the same YAML file, but version is 3.0
        
    syntax
        services
            we list the containers we'd like
            for each container image, we can specify the expected properties/commands from docker run
                image
                name
                volumes
                ports
                ...
                restart
                    if a container stops, it restarts
                depends_on
                    force waiting for another container to be up

    Note that by default all containers run with compose share the same virtual network
        that means all ports are accessible between them
        we dont need to expose ports
        but if another container is launched later outside, its ports are not visible

    docker-compose up
        YAML opened and conatiners started in the order we put them
    docker-compose down
        stop containers
        volumes are not erased

    we can have access to service (=container) information
        docker-compose logs <SERVICE>

Exercise 4

    See exercise notes.

# Module 3: Create your own images

Creating images

    We create a file named Dockerfile
    Typical structure/recipy
        FROM php:7.1-apache
            we specify the base or parent image
            FROM <image name>[:tag]
            FROM scratch
                when we want to create an image from scratch
        RUN
            we execute a command inside the containert
            typically, first we need to install all depencencies with a package manager
            RUN apt-get update && apt-get install -y \
                curl
                wget
                ...
            -y: yes to all
            \ try to put everything in one command line
            packages: put them in alphabetical order
        COPY
            then, we need to copy local files to the container
        ENTRYPOINT
            say which binary is executed when container starts
            ENTRYPOINT ["exec", "param1"]
            ENTRYPOINT ["entrypoint.sh"]
            ENTRYPOINT ["/bin/sh","-c"]
        CMD
            the command passed to ENTRYPOINT
            CMD ["exec", "param1"]
            for example: 
                FROM ubuntu
                ENTRYPOINT ["/bin/cat"]
                CMD ["/etc/os-release"]
            the main difference is that we can overwrite CMD when runnning the container
            note that ENTRYPOINT and CMD are not necessary
            if not written, the ones in the base image are taken
        WORKDIR
            we say which is the working directory inside the container
        EXPOSE
            ports that are exposed
            it's a good practice to write them
            however, without EXPOSE, we can always use -p
            but -P works only if we have EXPOSE
        USER <user>[:<group>]
            username of the user inside of the container
        ARG <name>[=<default value>]
            the only instruction used before from
            once used, it disappears
            we pass through --build-arg the value of the <name> used

            ARG IMAGE=python:3.9
                default value for IMAGE
            FROM $IMAGE
            ...
            docker build --build-arg IMAGE=python:3.8
                now, default value is overwritten
        ENV
        RUN
    After writing the Dockerfile, we build the image
        docker build -t <image name> <context>
            context: path wehere all the necessary files are
    
Exercise 5

    See exercise.

Optimizing images

    When we re-build, the cache is usually used.
    Each line/command in the Dockerfile is a layer which is built, hashed and stacked.
    If we do not change commands, in a sequence, no new layers are built.
    Therefore, COPY should go at the end
        because if the copied source files are changed locally
        their cchecksum is different
        and a new layer must be created, even if the command in the Dockerfile is the same

    Note that the sum of layer sizes yields the size of the image
        it is like in git: every new layer added is stacked
        even if we remove the layer (the commit), it is still in the image

        that is important for compiled code: every compilation is an added information
        for that, we can use multistage builds

        MULTISTAGE builds
            in a Dockerfile, we create compile the binaries
            in another Dockerfile or in following section of the same file
            we import with COPY --from the binaries

    docker history <image name>
        we see all layers

    We want to build our images continuously: every time we change our code
        therefore, it makes sense to optmize build-time
    
Exercise 6

    See exercise.

Best practices

    Containers must be ephemeral: disposable!
        that doesn't mean they don't last long up in time
    Concatenate run instructions with && and \
    Do not install any shit which is not necessary    
    Remove temp files with rm
    Order instructions by refresh frequency
        to leverage cached layers
    Use .dockerignore, equivalent to .gitignore; add, at least:
        .git
    Use the instruction USER
    Use tags for images
    Avoid the use of ADD, instead use COPY
        ADD is more powerful, though
        it can download files from internet
        it can also decompress images

# Module 4: Publishing images

We login to a registry and push there

    docker login -u <username> -p <token> registry.gitlab.com
        if we do not add a registry URL, it logs to docker hub
    docker build ...
    docker push <user>/<reponame>:<tag>
    docker logout

Registries in Vicomtech

    https://gitlab.vicomtech.es
        non accessible from outside
    https://quay.io
        accessible from outside

    docker hub: https://hub.docker.com

    Note that the same image can have different tags
        6.5.0 = 6.5 = 6

Exercise 7

    See exercise.

Utilities / Troubleshooting

    docker stats
    docker top <container>
    docker-compose top <service>
    docker conatiner|image inspect <name>
    docker exec -ti <name/id> sh
        open a terminal
    docker-compose exec <name> sh
        same, but for docker compose, note we need no -ti
    docker image ls <patter*>
    docker image ls my_*
        we can also use --filter
    docker system df
        size in disk of images, containers, volumes
    docker system df -v
        same, but verbose, more info
        note that layers are shared between different images
        intermediate stage image builds appear as <none>
            aka dangling images, not tagged
            we can remove them with docker image prune
    docker image prune
        dangling images removed
    docker image prune -a
        all images not being used in comntainers removed
        be careful
    docker system prune

    ctop
    lazydocker

Exercise 8
Exercise 9

Windows particularities

    We use the Linux subsystem from Windows: WSL2
    Line endings: be aware of them: CRLF vs LF
    You cannot ping containers
    File permissions are different if the files are on Windows and not on the WSL subsystem
    