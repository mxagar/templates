{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Object Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optical Flow = Pattern of apparent motion of image objects between two consecutive frames caused by the movement of the camera.\n",
    "Assumptions:\n",
    "- Pixel intensities don't change between consecutive frames\n",
    "- Neighboring pixels have similar motion\n",
    "\n",
    "The method we use is the **Lucas-Kanade** method.\n",
    "The method doesn't know whether the camera is moving or the scene/object is moving.\n",
    "\n",
    "How it works:\n",
    "- We select some points on a frame: we can define the region which contains a face that was detected with the techniques learned in section 6 or we efine a set of **sparse** (key-)points.\n",
    "- The algorithm will try to follow/track those points on the next frame by detecting them using the assumptions specified above.\n",
    "\n",
    "But what if we want to track **all** the points on a frame? Lucas-Kanade doesn't do that, but the **Gunner Farnebäck**'s algorithm does -- this is called **dense optical flow**: we look at the entire frame and highlight the points that are moving: returned image's pixel intensity means amount of motion: black, no motion; color depending on movement direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 Lucas-Kanade: Sparse Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lucas-Kanade works with sparse points\n",
    "# We are going to use the Shi-Tomasi corners as sparse points to track\n",
    "# We prepare the param dictionary for the corner detector here\n",
    "# We can tune these params; note: max num of points selected 10\n",
    "corner_track_params = dict(maxCorners=10,\n",
    "                           qualityLevel=0.3,\n",
    "                           minDistance=7,\n",
    "                           blockSize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the Lucas-Kanade method\n",
    "# - window size: integration window size, trade-off between small & larger windows: small more senstive to smaller motions, bat misses large motoins and sometimes delivers noise\n",
    "# - maxLevel: Lucas-Kanade uses image pyramids (0: org resolution, 1: 1/2 resolution, 2: 1/4)\n",
    "# - criteria (to stop iterative method): number of iterations and error threshold to stop; note the order of criteria & values is different!\n",
    "lk_params = dict(winSize=(200,200),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS|cv2.TERM_CRITERIA_COUNT,10, 0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(0) # webcam input\n",
    "cap = cv2.VideoCapture('../../data/hand_move.mp4') # recorded video input\n",
    "# Grab first frame; each frame becomes the previous frame\n",
    "ret, prev_frame = cap.read()\n",
    "# The method works with mono images\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "# Points to track: Shi-Tomasi corners\n",
    "prevPoints = cv2.goodFeaturesToTrack(prev_gray,mask=None,**corner_track_params) # ** passes a dictionary\n",
    "# Visualization purposes\n",
    "mask = np.zeros_like(prev_frame) # matching mask with 0s\n",
    "ret = True\n",
    "while ret:\n",
    "    ret, frame = cap.read()\n",
    "    if (ret):\n",
    "        # gray\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # OPTICAL FLOW: Pyramid Lucas-Kanade\n",
    "        # input: previous gray, current gray, previous points, params\n",
    "        # output: status = 1 iff point has been found\n",
    "        nextPoints, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prevPoints, None, **lk_params)\n",
    "        # Select found points: previous and new\n",
    "        good_new = nextPoints[status==1]\n",
    "        good_prev = prevPoints[status==1]\n",
    "        # Draw points and movement vectors previous -> new\n",
    "        for i, (new,prev) in enumerate(zip(good_new,good_prev)):\n",
    "            # ravel() = reshape(-1) = flatten\n",
    "            x_new, y_new = new.ravel()\n",
    "            x_prev, y_prev = prev.ravel()\n",
    "            # Draw vector/line\n",
    "            mask = cv2.line(mask, (x_new,y_new), (x_prev,y_prev), (0,255,0), 3)\n",
    "            # Draw point circle\n",
    "            frame = cv2.circle(frame, (x_new,y_new), 8, (0,0,255), -1)\n",
    "        # We add the image and the mask (themask contains only lines and circles)\n",
    "        img = cv2.add(frame,mask)\n",
    "        cv2.imshow('tracking', img)\n",
    "        # wait for ESC\n",
    "        k = cv2.waitKey(30) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "        # Update: current values (frame and points) become previous\n",
    "        prev_gray = frame_gray.copy()\n",
    "        prevPoints = good_new.reshape(-1,1,2)\n",
    "    else:\n",
    "        break\n",
    "# Clear\n",
    "# Note: on my mac, this doesn't work\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2 Dense Optical Flow: Farnabäck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the entire image and color points that we believe are moving.\n",
    "Basically, the same structure is used but with the function `cv2.calcOpticalFlowFarneback()`. Its params are:\n",
    "* prev first 8-bit single-channel input image.\n",
    "* next second input image of the same size and the same type as prev.\n",
    "* flow computed flow image that has the same size as prev and type CV_32FC2.\n",
    "* pyr_scale parameter, specifying the image scale (\\<1) to build pyramids for each image\n",
    "    * pyr_scale=0.5 means a classical pyramid, where each next layer is twice smaller than the previous one.\n",
    "    \n",
    "* levels number of pyramid layers including the initial image; levels=1 means that no extra layers are created and only the original images are used.\n",
    "* winsize averaging window size\n",
    "    * larger values increase the algorithm robustness to image\n",
    "* noise and give more chances for fast motion detection, but yield more blurred motion field.\n",
    "* iterations number of iterations the algorithm does at each pyramid level.\n",
    "* poly_n size of the pixel neighborhood used to find polynomial expansion in each pixel\n",
    "    * larger values mean that the image will be approximated with smoother surfaces, yielding more robust algorithm and more blurred motion field, typically poly_n =5 or 7.\n",
    "* poly_sigma standard deviation of the Gaussian that is used to smooth derivatives used as a basis for the polynomial expansion; for poly_n=5, you can set poly_sigma=1.1, for poly_n=7, a good value would be poly_sigma=1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(0) # webcam input\n",
    "cap = cv2.VideoCapture('../../data/hand_move.mp4') # recorded video input\n",
    "ret, frame1 = cap.read()\n",
    "# Get gray scale image of first frame and make a mask in HSV color\n",
    "prvsImg = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "# Mask for visualization - HSV colormap\n",
    "hsv_mask = np.zeros_like(frame1)\n",
    "hsv_mask[:,:,1] = 255 # fully saturated; the other channels are going to be movement angle & magnitude!\n",
    "ret = True\n",
    "while ret:\n",
    "    ret, frame2 = cap.read()\n",
    "    if ret:\n",
    "        nextImg = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "        # Check out the markdown text above for a break down of these paramters, most of these are just suggested defaults\n",
    "        # output: flow is a 2-channel movement vector field with x (channel 0) & (1) y movement values\n",
    "        # we transaform it later to polar coords to visualize it with HSV color mapping\n",
    "        flow = cv2.calcOpticalFlowFarneback(prvsImg,nextImg, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        # Color the channels based on the angle of travel\n",
    "        # Pay close attention to your video, the path of the direction of flow will determine color!\n",
    "        mag, ang = cv2.cartToPolar(flow[:,:,0], flow[:,:,1], angleInDegrees=True)\n",
    "        hsv_mask[:,:,0] = ang/2 # we scale to 180 deg in order to work with half the hues, it's easier to understand visualization\n",
    "        hsv_mask[:,:,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX) # map magnitude values to [0,255]\n",
    "        # Convert back to BGR to show with imshow from cv\n",
    "        bgr = cv2.cvtColor(hsv_mask,cv2.COLOR_HSV2BGR)\n",
    "        cv2.imshow('frame2',bgr)\n",
    "        # Wait for ESC\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        # Set the previous image as the next iamge for the loop\n",
    "        prvsImg = nextImg\n",
    "# Clear\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
