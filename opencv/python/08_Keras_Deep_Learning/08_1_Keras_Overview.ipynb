{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Deep Learning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Keras Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect whether bank notes are forged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# read CSV tables\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 columns x 1372 rows (samples)\n",
    "# column 0-3: input features, already extracted\n",
    "# column 4: label = 0 forgery, 1 real\n",
    "data = genfromtxt('../../data/bank_note_data.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699,   0.     ],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ,   0.     ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645,   0.     ],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ,   1.     ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ,   1.     ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ,   1.     ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Scikit-Learn for splitting the dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split Shift TAB, scroll down to example\n",
    "# it is important to randomize\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8734  , -0.033118, -0.20165 ,  0.55774 ],\n",
       "       [ 2.0177  ,  1.7982  , -2.9581  ,  0.2099  ],\n",
       "       [-0.36038 ,  4.1158  ,  3.1143  , -0.37199 ],\n",
       "       ...,\n",
       "       [-7.0364  ,  9.2931  ,  0.16594 , -4.5396  ],\n",
       "       [-3.4605  ,  2.6901  ,  0.16165 , -1.0224  ],\n",
       "       [-3.3582  , -7.2404  , 11.4419  , -0.57113 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "919"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(919,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.1116"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.2869"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a scaler object,\n",
    "# fit the X_train to it (min-max range)\n",
    "# and then transform it (scale to the range [0,1])\n",
    "scaler_object = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_object.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler_object.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: we fit (select scaling min-max range) to the TRAIN split only,\n",
    "# because otherwise we're extracting info from the test split\n",
    "# if a test sample has the max (peak) value!\n",
    "scaled_X_test = scaler_object.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.02679563427227"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0010694864308909147"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_test.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a neural network model & train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "# We use fully-connected layers in this example\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model, then add the layers\n",
    "model = Sequential()\n",
    "\n",
    "# Add input layer: neurons, input dimenstion, activation\n",
    "# input dimension is necessary only for the input layer\n",
    "model.add(Dense(4, input_dim=4, activation='relu'))\n",
    "\n",
    "# Add hidden layer: neurons, activation function\n",
    "# Often we use something between 1x - 2x the neurons in the input layer\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add ouput layer\n",
    "# The output layer should have the sigmoid activation to fit the result to [0,1]\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compile the model and define\n",
    "# loss function, optimization strategy, the metric used\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 69\n",
      "Trainable params: 69\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 1s - loss: 0.7442 - acc: 0.5495\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.7063 - acc: 0.5495\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6835 - acc: 0.5495\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6623 - acc: 0.5506\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6453 - acc: 0.5713\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6332 - acc: 0.6115\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6221 - acc: 0.6464\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6117 - acc: 0.6670\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6023 - acc: 0.6703\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.5923 - acc: 0.6910\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.5823 - acc: 0.7062\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.5719 - acc: 0.7291\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.5619 - acc: 0.7432\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.5508 - acc: 0.7508\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.5399 - acc: 0.7573\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.5295 - acc: 0.7661\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.5180 - acc: 0.7900\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.5077 - acc: 0.7769\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.4975 - acc: 0.8172\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.4872 - acc: 0.8063\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.4762 - acc: 0.8270\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.4657 - acc: 0.8368\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.4554 - acc: 0.8553\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.4449 - acc: 0.8553\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.4352 - acc: 0.8607\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.4252 - acc: 0.8760\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.4159 - acc: 0.8770\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.4067 - acc: 0.8912\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.3976 - acc: 0.8923\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.3892 - acc: 0.8977\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.3806 - acc: 0.9010\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.3719 - acc: 0.9021\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.3638 - acc: 0.9129\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.3561 - acc: 0.9151\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.3483 - acc: 0.9217\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.3410 - acc: 0.9260\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.3337 - acc: 0.9304\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.3271 - acc: 0.9238\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.3201 - acc: 0.9369\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.3138 - acc: 0.9369\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.3072 - acc: 0.9358\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.3015 - acc: 0.9412\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.2949 - acc: 0.9445\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.2894 - acc: 0.9478\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.2836 - acc: 0.9467\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.2779 - acc: 0.9499\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.2727 - acc: 0.9510\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.2682 - acc: 0.9521\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.2624 - acc: 0.9543\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.2578 - acc: 0.9532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc3c9a99e8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model: X & y are passed, and the number of epochs\n",
    "# In an epoch, teh whole dataset is used for training once\n",
    "# With verbose, the loss and accuracy are displayed for each epoch\n",
    "model.fit(scaled_X_train, y_train, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer test split and compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We display the confussion matrix with TP, TN, FP, FN\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[248,   9],\n",
       "       [ 12, 184]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.96      0.96       257\n",
      "        1.0       0.95      0.94      0.95       196\n",
      "\n",
      "avg / total       0.95      0.95      0.95       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_super_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = load_model('my_super_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can infer as before\n",
    "y_pred = newmodel.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
