{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "\n",
    "I modified the notebook orginally created by JM Portilla (Pierian Data Inc.).\n",
    "\n",
    "Tensorboard is a dashboard that visualizes how the network is trained, eg., the weight values along the epochs are displayed, etc.\n",
    "\n",
    "Official tutorial: https://www.tensorflow.org/tensorboard/get_started\n",
    "\n",
    "**Install**:\n",
    "`pip/3 install tensorboard`\n",
    "\n",
    "**Usage**:\n",
    "1. We instantiate a TensorBoard callback and pass it to `model.fit()`; the callback logs can save many different data\n",
    "2. Then, we launch tensorboard in the terminal: `tensorboard --logdir=path_to_your_logs`\n",
    "3. We open the tensorboard dashboard with browser at: http://localhost:6006/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1',axis=1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the TersorBoard callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Tensorboard Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments to instantiate `TensorBoard` (from the help docstring):\n",
    "- `log_dir`: directory of log files used by TensorBoard\n",
    "- `histogram_freq`: frequency (in epochs) at which to compute activation and\n",
    "weight histograms for the layers of the model. If set to 0, histograms\n",
    "won't be computed. Validation data (or split) must be specified for\n",
    "histogram visualizations.\n",
    "- `write_graph`: whether to visualize the graph in TensorBoard. The log file\n",
    "can become quite large when write_graph is set to True.\n",
    "write_images: whether to write model weights to visualize as image in\n",
    "TensorBoard.\n",
    "- `update_freq`: `'batch'` or `'epoch'` or integer. When using `'batch'`,\n",
    "writes the losses and metrics to TensorBoard after each batch. The same\n",
    "applies for `'epoch'`. If using an integer, let's say `1000`, the\n",
    "callback will write the metrics and losses to TensorBoard every 1000\n",
    "samples. Note that writing too frequently to TensorBoard can slow down\n",
    "your training.\n",
    "- `profile_batch`: Profile the batch to sample compute characteristics. By\n",
    "default, it will profile the second batch. Set `profile_batch=0` to\n",
    "disable profiling. Must run in TensorFlow eager mode.\n",
    "- `embeddings_freq`: frequency (in epochs) at which embedding layers will\n",
    "be visualized. If set to 0, embeddings won't be visualized.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-02-06--1558'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H%M\")\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOWS: Use \"logs\\\\fit\"\n",
    "# MACOS/LINUX: Use \"logs/fit\"\n",
    "\n",
    "# Path where log files are stored needs to be specified\n",
    "# Log files are necessary for the visualizations done in tensorboard\n",
    "# Always use `logs/fit` and then what you want (eg, a timestamp) \n",
    "log_directory = 'logs/fit/'+ timestamp\n",
    "# Later, when we launch tensorboard in the Terminal:\n",
    "# --logdir=logs/fit/<timestamp>\n",
    "\n",
    "board = TensorBoard(log_dir=log_directory,histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network / Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=30,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pass th early stop and the (tensor-)board as callbacks\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop,board]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Launch TensorBoard\n",
    "\n",
    "Open terminal and start TensorBoard passing our path to the log files:\n",
    "\n",
    "```bash\n",
    "cd <path/to/our/project>\n",
    "tensorboard --logdir=<path/to/your/logs>\n",
    "tensorboard --logdir=logs/fit/<timestamp>\n",
    "```\n",
    "\n",
    "Open the TensorBoard dashboard with the broswer on [http://localhost:6006/](http://localhost:6006/)\n",
    "\n",
    "More info:\n",
    "https://www.tensorflow.org/tensorboard/\n",
    "\n",
    "Some comments on the TensorBoard dashboard:\n",
    "- Loss is ploted (smoothed or not) for train & validation split\n",
    "- Images (activation maps?) can be visualized in different stages of the network -- it makes sense for CNNs processing images\n",
    "- The graph of the model is visualized\n",
    "- Weight (& bias) ranges during epochs visualized\n",
    "- Histograms of weights (& biases) during epochs visualized\n",
    "- Projector: Really cool data visualization (high-dim data projected) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
